{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensor Based Activity Recoginition \n",
    "Challenge: cdl1 - Sensor based Activity Recognition  \n",
    "Team: Lea BÃ¼tler, Manjavy Kirupa, Etienne Roulet, Si Ben Tran  \n",
    "\n",
    "Aufgabe: DL Modell erstellen\n",
    "\n",
    "Hier in diesem Notebook erstellen wir unsere Deep Learning Modelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import dataclasses\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "tf.debugging.set_log_device_placement(False)\n",
    "\n",
    "# datetime as filename for logging\n",
    "now = datetime.now()\n",
    "date_time_string = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, filename = f\"{date_time_string}.txt\", filemode='a')\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "# Static Parameters\n",
    "@dataclass\n",
    "class Parameters():\n",
    "    batch_size: int = 128\n",
    "    epochs: int = 10\n",
    "    verbosity: str = \"1\"\n",
    "    step_size: int = 374\n",
    "    number_folds: int = 2\n",
    "    output_size: int = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time</th>\n",
       "      <th>Accelerometer_x</th>\n",
       "      <th>Accelerometer_y</th>\n",
       "      <th>Accelerometer_z</th>\n",
       "      <th>Gyroscope_x</th>\n",
       "      <th>Gyroscope_y</th>\n",
       "      <th>Gyroscope_z</th>\n",
       "      <th>Magnetometer_x</th>\n",
       "      <th>Magnetometer_y</th>\n",
       "      <th>Magnetometer_z</th>\n",
       "      <th>Orientation_qx</th>\n",
       "      <th>Orientation_qy</th>\n",
       "      <th>Orientation_qz</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>class</th>\n",
       "      <th>id_combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-27 15:02:17.156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.722</td>\n",
       "      <td>1.278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.21775</td>\n",
       "      <td>-0.719579</td>\n",
       "      <td>0.631111</td>\n",
       "      <td>01_SamsungA22-2023-02-27_15-02-03</td>\n",
       "      <td>Ben_Tran</td>\n",
       "      <td>Laufen</td>\n",
       "      <td>01_SamsungA22-2023-02-27_15-02-03Ben_TranLaufen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                     time  Accelerometer_x  Accelerometer_y  \\\n",
       "0           1  2023-02-27 15:02:17.156              0.0            9.722   \n",
       "\n",
       "   Accelerometer_z  Gyroscope_x  Gyroscope_y  Gyroscope_z  Magnetometer_x  \\\n",
       "0            1.278          0.0          0.0          0.0             0.0   \n",
       "\n",
       "   Magnetometer_y  Magnetometer_z  Orientation_qx  Orientation_qy  \\\n",
       "0             0.0             0.0        -0.21775       -0.719579   \n",
       "\n",
       "   Orientation_qz                                 id      user   class  \\\n",
       "0        0.631111  01_SamsungA22-2023-02-27_15-02-03  Ben_Tran  Laufen   \n",
       "\n",
       "                                       id_combined  \n",
       "0  01_SamsungA22-2023-02-27_15-02-03Ben_TranLaufen  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"Alle_Messungen_trimmed.csv\") \n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the string time column to datetime\n",
    "epoch = pd.Timestamp('1970-01-01')\n",
    "\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['time'] = (df['time'] - epoch).apply(lambda x: int(x.total_seconds() * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns that are not needed\n",
    "df = df.drop(columns=[\"id\", \"user\", \"id_combined\"])\n",
    "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "# get all types of the df\n",
    "#df['time'] = pd.to_datetime(df['time'])\n",
    "#df['time'] = df['time'].astype('int64')//1e9\n",
    "le = LabelEncoder()\n",
    "df[\"class\"] = le.fit_transform(df[\"class\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without rolling windows but with timesteps\n",
    "X = df.values[:, 1:13]\n",
    "y = df.values[:, 13]\n",
    "\n",
    "# Reshape X to 3D format (samples, timesteps, features)\n",
    "timesteps = 1  # You can choose a different number of timesteps based on the nature of your data\n",
    "n_features = X.shape[1]\n",
    "X = X.reshape(-1, timesteps, n_features)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=6)\n",
    "y_test = to_categorical(y_test, num_classes=6)\n",
    "# calculate_rolling_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the window size and step size\n",
    "window_size = 5\n",
    "step_size = 1\n",
    "\n",
    "# Reshape X to 2D format (samples, features)\n",
    "X = df.values[:, 1:13]\n",
    "\n",
    "# Define y\n",
    "y = df[\"class\"].values\n",
    "\n",
    "# Create a sliding window of X with the specified window and step sizes\n",
    "X_windows = np.array([X[i:i+window_size,:] for i in range(0,X.shape[0]-window_size+1,step_size)])\n",
    "\n",
    "# Reshape X_windows to 3D format (samples, timesteps, features)\n",
    "timesteps = X_windows.shape[1]\n",
    "n_features = X_windows.shape[2]\n",
    "X_windows = X_windows.reshape(-1, timesteps, n_features)\n",
    "\n",
    "# Create the corresponding y labels for the sliding windows\n",
    "y_windows = np.array([y[i+window_size-1] for i in range(0,X.shape[0]-window_size+1,step_size)])\n",
    "y_windows = to_categorical(y_windows, num_classes=6)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_windows, y_windows, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log it with logging\n",
    "logging.info(f\"X.shape: {X.shape}, y.shape: {y.shape}, X_train.shape: {X_train.shape}, y_train.shape: {y_train.shape}, X_test.shape: {X_test.shape}, y_test.shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "# Load data and preprocess\n",
    "# split train dataset into x_train and y_train\n",
    "# make temporary pointer to the data cause i dont like the uppercase\n",
    "x_train = X_train\n",
    "x_test = X_test\n",
    "y_train = y_train\n",
    "y_test = y_test\n",
    "    \n",
    "\n",
    "# Something like this as first Model\n",
    "def create_model_1():\n",
    "    model = tf.keras.Sequential([\n",
    "        # Add a 1D convolutional layer\n",
    "        tf.keras.layers.Conv1D(filters=128, kernel_size=2, activation='relu', padding='same', input_shape=(timesteps, n_features)),\n",
    "        \n",
    "        # Add LSTM layer\n",
    "        tf.keras.layers.LSTM(100),\n",
    "\n",
    "        # Add a dense output layer\n",
    "        tf.keras.layers.Dense(6, activation='softmax')  # Change activation function based on the nature of the output\n",
    "    ])\n",
    "    model.compile(optimizer='adam',   loss='categorical_crossentropy', metrics=['accuracy'])  # Change the loss function based on the nature of the output\n",
    "    return model\n",
    "\n",
    "\n",
    "# Something like this as second Model\n",
    "def create_model_2():\n",
    "    model = tf.keras.Sequential([\n",
    "        # Add a 1D convolutional layer\n",
    "        tf.keras.layers.Conv1D(filters=256, kernel_size=2, activation='relu', padding='same', input_shape=(timesteps, n_features)),\n",
    "        \n",
    "        # Add LSTM layer\n",
    "        tf.keras.layers.LSTM(100),\n",
    "\n",
    "        # Add a dense output layer\n",
    "        tf.keras.layers.Dense(6, activation='softmax')  # Change activation function based on the nature of the output\n",
    "    ])\n",
    "    model.compile(optimizer='adam',   loss='categorical_crossentropy', metrics=['accuracy'])  # Change the loss function based on the nature of the output\n",
    "    return model\n",
    "\n",
    "# Something like this as Third Model\n",
    "def create_model_3():\n",
    "    model = tf.keras.Sequential([\n",
    "        # Add a 1D convolutional layer\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=4, activation='relu', padding='same', input_shape=(timesteps, n_features)),\n",
    "        \n",
    "        # Add LSTM layer\n",
    "        tf.keras.layers.LSTM(100),\n",
    "\n",
    "        # Add a dense output layer\n",
    "        tf.keras.layers.Dense(6, activation='softmax')  # Change activation function based on the nature of the output\n",
    "    ])\n",
    "    model.compile(optimizer='adam',   loss='categorical_crossentropy', metrics=['accuracy'])  # Change the loss function based on the nature of the output\n",
    "    return model\n",
    "\n",
    "def create_model_4():\n",
    "    model = tf.keras.Sequential([\n",
    "        # Add a 1D convolutional layer\n",
    "        tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', padding='same', input_shape=(timesteps, n_features)),\n",
    "        \n",
    "        # Add LSTM layer\n",
    "        tf.keras.layers.LSTM(100),\n",
    "\n",
    "        # Add a dense output layer\n",
    "        tf.keras.layers.Dense(6, activation='softmax')  # Change activation function based on the nature of the output\n",
    "    ])\n",
    "    model.compile(optimizer='adam',   loss='categorical_crossentropy', metrics=['accuracy'])  # Change the loss function based on the nature of the output\n",
    "    return model\n",
    "\n",
    "best_model_history = None  # Keep track of the best model's history\n",
    "\n",
    "model_histories = []\n",
    "# Perform cross-validation\n",
    "models = [create_model_1,create_model_2,create_model_3,create_model_4]\n",
    "best_model = None\n",
    "num_folds = Parameters.number_folds\n",
    "# Shuffel the Data with the Folds\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "fold_acc_scores = []\n",
    "\n",
    "for i, (train, test) in enumerate(kfold.split(x_train, y_train)):\n",
    "    logging.info(f'Fold {i+1}')\n",
    "    train_x, train_y = x_train[train], y_train[train]\n",
    "    test_x, test_y = x_train[test], y_train[test]\n",
    "    \n",
    "    fold_histories = []\n",
    "\n",
    "    \n",
    "    for j, model_creator in enumerate(models):\n",
    "        model = model_creator()\n",
    "        logging.info(f'Model {j+1}')\n",
    "        history = model.fit(train_x, train_y, epochs=Parameters.epochs, batch_size=Parameters.batch_size, validation_data=(test_x, test_y), verbose=Parameters.verbosity)\n",
    "        test_loss, acc = model.evaluate(test_x, test_y, verbose=Parameters.verbosity)\n",
    "        logging.info(f'Validation accuracy: {acc}')\n",
    "        \n",
    "        fold_histories.append(history.history)\n",
    "        \n",
    "        for epoch in range(Parameters.epochs):\n",
    "            # Log accuracy after each epoch\n",
    "            acc_epoch = history.history['val_accuracy'][epoch]\n",
    "            logging.info(f'Epoch {epoch + 1}, Validation accuracy: {acc_epoch}')\n",
    "        fold_acc_scores.append((i, j, acc))\n",
    "        \n",
    "        if best_model_history is None or acc > best_model_acc:\n",
    "            best_model_history = history\n",
    "            best_model = model  # Store the trained model instance\n",
    "            best_model_acc = acc\n",
    "    \n",
    "    model_histories.append(fold_histories)\n",
    "\n",
    "# Find the best model\n",
    "best_model_index = np.argmax([score[2] for score in fold_acc_scores])\n",
    "best_fold_idx, best_model_idx, _ = max(fold_acc_scores, key=lambda x: x[2])\n",
    "best_model_history = model_histories[best_fold_idx][best_model_idx]\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
    "logging.info(f'Test accuracy {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual Test with unseen Data Future it should be the webapp\n",
    "df_yvo = df_yvo.drop(columns=[\"id\", \"user\", \"id_combined\"])\n",
    "df_yvo.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['time'] = (df['time'] - epoch).apply(lambda x: int(x.total_seconds() * 1000))\n",
    "# get all types of the df\n",
    "X = df_yvo.values[:, 1:13]\n",
    "print(X)\n",
    "\n",
    "\n",
    "# Create a sliding window of X with the specified window and step sizes\n",
    "X_windows = np.array([X[i:i+window_size,:] for i in range(0,X.shape[0]-window_size+1,step_size)])\n",
    "\n",
    "# Reshape X_windows to 3D format (samples, timesteps, features)\n",
    "timesteps = X_windows.shape[1]\n",
    "n_features = X_windows.shape[2]\n",
    "print(n_features)\n",
    "X_windows = X_windows.reshape(-1, timesteps, n_features)\n",
    "X_windows = X_windows.astype('float32')\n",
    "\n",
    "# Create the corresponding y labels for the sliding windows\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "\n",
    "y_pred = best_model.predict(X_windows)\n",
    "# Get the predicted class probabilities for each input window\n",
    "y_pred_probs = best_model.predict(X_windows)\n",
    "\n",
    "# Get the predicted class labels for each input window\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Print the predicted class labels\n",
    "# get the median of the predicted labels\n",
    "sol = np.median(y_pred_labels)\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the training process\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(best_model_history['loss'])\n",
    "# summarize history for accuracy\n",
    "plt.plot(best_model_history['accuracy'])\n",
    "plt.plot(best_model_history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(best_model_history['loss'])\n",
    "plt.plot(best_model_history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarise best model\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "#for multiclass classification\n",
    "y_pred = best_model.predict(x_test)\n",
    "y_test_labels = y_test.argmax(axis=1)\n",
    "y_pred_labels = y_pred.argmax(axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "# get f1 score of each class\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_test_labels, y_pred_labels, average=None)\n",
    "# get f1 score of each class\n",
    "\n",
    "disp.plot()\n",
    "plt.show()\n",
    "display(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Baseline vs best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot graph for learning curve and loss curve from baseline and best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print loss and accuracy for best model over epoch and steps plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Model for using in tensorflow.js\n",
    "!mkdir -p saved_model\n",
    "best_model.save('saved_model/sensor_model')\n",
    "best_model.save('saved_model/sensor_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weight for the Js Model\n",
    "best_model.save_weights('./checkpoints/my_checkpoint')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload model to server to download it on tensorflow js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump_session('notebook_env.db')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
